{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing \n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify device\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>propertyId</th>\n",
       "      <th>propertyName</th>\n",
       "      <th>propertyDescription</th>\n",
       "      <th>passageText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>EDUCATED_AT</td>\n",
       "      <td>Describes the relationship between a person an...</td>\n",
       "      <td>When she founded Apex Legal Document Preparati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SUBSIDIARY_OF</td>\n",
       "      <td>Describes the relationship between a parent co...</td>\n",
       "      <td>Tata Chemicals Europe (formerly Brunner Mond (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>DATE_OF_DEATH</td>\n",
       "      <td>Describes the date of death of a person.</td>\n",
       "      <td>After five successful albums and extensive tou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>NATIONALITY</td>\n",
       "      <td>Describes he country of a person's citizenship...</td>\n",
       "      <td>He is a member of Phi Beta Kappa and was a Ful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>NATIONALITY</td>\n",
       "      <td>Describes he country of a person's citizenship...</td>\n",
       "      <td>H.E. Sheikh Abdullah bin Mohammed bin Saud Al ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   propertyId   propertyName  \\\n",
       "0           9    EDUCATED_AT   \n",
       "1           1  SUBSIDIARY_OF   \n",
       "2          14  DATE_OF_DEATH   \n",
       "3          10    NATIONALITY   \n",
       "4          10    NATIONALITY   \n",
       "\n",
       "                                 propertyDescription  \\\n",
       "0  Describes the relationship between a person an...   \n",
       "1  Describes the relationship between a parent co...   \n",
       "2           Describes the date of death of a person.   \n",
       "3  Describes he country of a person's citizenship...   \n",
       "4  Describes he country of a person's citizenship...   \n",
       "\n",
       "                                         passageText  \n",
       "0  When she founded Apex Legal Document Preparati...  \n",
       "1  Tata Chemicals Europe (formerly Brunner Mond (...  \n",
       "2  After five successful albums and extensive tou...  \n",
       "3  He is a member of Phi Beta Kappa and was a Ful...  \n",
       "4  H.E. Sheikh Abdullah bin Mohammed bin Saud Al ...  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table(\"input_data.tsv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3977, 4)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PLACE_OF_BIRTH           0.119940\n",
       "DATE_FOUNDED             0.078200\n",
       "EMPLOYEE_OR_MEMBER_OF    0.077948\n",
       "SUBSIDIARY_OF            0.077445\n",
       "HEADQUARTERS             0.072165\n",
       "POLITICAL_AFFILIATION    0.068645\n",
       "NATIONALITY              0.064622\n",
       "CHILD_OF                 0.063113\n",
       "DATE_OF_DEATH            0.062107\n",
       "DATE_OF_BIRTH            0.057581\n",
       "EDUCATED_AT              0.054815\n",
       "FOUNDED_BY               0.054312\n",
       "PLACE_OF_RESIDENCE       0.051798\n",
       "CEO                      0.050792\n",
       "SPOUSE                   0.046517\n",
       "Name: propertyName, dtype: float64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['propertyName'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 14,  4,  9,  8,  7, 13,  0, 11,  2, 12, 10,  6,  1,  3])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = preprocessing.LabelEncoder() \n",
    "  \n",
    "# Encode labels in column 'species'. \n",
    "df['encodedpropertyName']= label_encoder.fit_transform(df['propertyName']) \n",
    "  \n",
    "df['encodedpropertyName'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, val_text, train_labels, val_labels = train_test_split(df['passageText'], df['encodedpropertyName'], \n",
    "                                                                    random_state=2018, \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    stratify=df['propertyId'])\n",
    "\n",
    "test_df = pd.read_table(\"test_data.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = test_df['passageText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data\n",
    "text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\n",
    "\n",
    "# encode text\n",
    "sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 2023, 2003, 1037, 14324, 2944, 14924, 4818, 102, 0], [101, 2057, 2097, 2986, 1011, 8694, 1037, 14324, 2944, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "print(sent_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f159708ca60>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get length of all the messages in the train set\n",
    "seq_len = [len(i.split()) for i in train_text]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1938: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")\n",
    "\n",
    "tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train set\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "# for validation set\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "# for test set\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#define a batch size\n",
    "batch_size = 32\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "      \n",
    "      super(BERT_Arch, self).__init__()\n",
    "\n",
    "      self.bert = bert \n",
    "      \n",
    "      # dropout layer\n",
    "      self.dropout = nn.Dropout(0.1)\n",
    "      \n",
    "      # relu activation function\n",
    "      self.relu =  nn.ReLU()\n",
    "\n",
    "      # dense layer 1\n",
    "      self.fc1 = nn.Linear(768,512)\n",
    "      \n",
    "      # dense layer 2 (Output layer)\n",
    "      self.fc2 = nn.Linear(512,15)\n",
    "\n",
    "      #softmax activation function\n",
    "      self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "\n",
    "      #pass the inputs to the model  \n",
    "      _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
    "      \n",
    "      x = self.fc1(cls_hs)\n",
    "\n",
    "      x = self.relu(x)\n",
    "\n",
    "      x = self.dropout(x)\n",
    "\n",
    "      # output layer\n",
    "      x = self.fc2(x)\n",
    "      \n",
    "      # apply softmax activation\n",
    "      x = self.softmax(x)\n",
    "\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert)\n",
    "\n",
    "# push the model to device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.31583924 1.05416667 0.85107034 1.15958333 1.07244701 1.21263617\n",
      " 0.85499232 1.22869757 0.92305141 1.03074074 0.55548902 1.28842593\n",
      " 0.97137871 1.43824289 0.86294574]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#compute the class weights\n",
    "class_wts = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n",
    "\n",
    "print(class_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class weights to tensor\n",
    "# weights= torch.tensor(class_wts,dtype=torch.float)\n",
    "# weights = weights.to(device)\n",
    "\n",
    "# loss function\n",
    "cross_entropy  = nn.NLLLoss() \n",
    "\n",
    "# number of training epochs\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "  \n",
    "  model.train()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save model predictions\n",
    "  total_preds=[]\n",
    "  \n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(train_dataloader):\n",
    "    \n",
    "    # progress update after every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "    # push the batch to gpu\n",
    "    batch = [r.to(device) for r in batch]\n",
    " \n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # clear previously calculated gradients \n",
    "    model.zero_grad()        \n",
    "\n",
    "    # get model predictions for the current batch\n",
    "    preds = model(sent_id, mask)\n",
    "\n",
    "    # compute the loss between actual and predicted values\n",
    "    loss = cross_entropy(preds, labels)\n",
    "\n",
    "    # add on to the total loss\n",
    "    total_loss = total_loss + loss.item()\n",
    "\n",
    "    # backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # model predictions are stored on GPU. So, push it to CPU\n",
    "    preds=preds.detach().cpu().numpy()\n",
    "\n",
    "    # append the model predictions\n",
    "    total_preds.append(preds)\n",
    "\n",
    "  # compute the training loss of the epoch\n",
    "  avg_loss = total_loss / len(train_dataloader)\n",
    "  \n",
    "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  #returns the loss and predictions\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "  \n",
    "  print(\"\\nEvaluating...\")\n",
    "  \n",
    "  # deactivate dropout layers\n",
    "  model.eval()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save the model predictions\n",
    "  total_preds = []\n",
    "\n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(val_dataloader):\n",
    "    \n",
    "    # Progress update every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      \n",
    "      # Calculate elapsed time in minutes.\n",
    "      elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "      # Report progress.\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "    # push the batch to gpu\n",
    "    batch = [t.to(device) for t in batch]\n",
    "\n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # deactivate autograd\n",
    "    with torch.no_grad():\n",
    "      \n",
    "      # model predictions\n",
    "      preds = model(sent_id, mask)\n",
    "\n",
    "      # compute the validation loss between actual and predicted values\n",
    "      loss = cross_entropy(preds,labels)\n",
    "\n",
    "      total_loss = total_loss + loss.item()\n",
    "\n",
    "      preds = preds.detach().cpu().numpy()\n",
    "\n",
    "      total_preds.append(preds)\n",
    "\n",
    "  # compute the validation loss of the epoch\n",
    "  avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 10\n",
      "  Batch    50  of     87.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 2.671\n",
      "Validation Loss: 2.609\n",
      "\n",
      " Epoch 2 / 10\n",
      "  Batch    50  of     87.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 2.563\n",
      "Validation Loss: 2.450\n",
      "\n",
      " Epoch 3 / 10\n",
      "  Batch    50  of     87.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 2.453\n",
      "Validation Loss: 2.414\n",
      "\n",
      " Epoch 4 / 10\n",
      "  Batch    50  of     87.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 2.355\n",
      "Validation Loss: 2.331\n",
      "\n",
      " Epoch 5 / 10\n",
      "  Batch    50  of     87.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 2.318\n",
      "Validation Loss: 2.325\n",
      "\n",
      " Epoch 6 / 10\n",
      "  Batch    50  of     87.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 2.275\n",
      "Validation Loss: 2.221\n",
      "\n",
      " Epoch 7 / 10\n",
      "  Batch    50  of     87.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 2.263\n",
      "Validation Loss: 2.176\n",
      "\n",
      " Epoch 8 / 10\n",
      "  Batch    50  of     87.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 2.185\n",
      "Validation Loss: 2.161\n",
      "\n",
      " Epoch 9 / 10\n",
      "  Batch    50  of     87.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 2.168\n",
      "Validation Loss: 2.130\n",
      "\n",
      " Epoch 10 / 10\n",
      "  Batch    50  of     87.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 2.139\n",
      "Validation Loss: 2.114\n"
     ]
    }
   ],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load weights of best model\n",
    "path = 'saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions for test data\n",
    "with torch.no_grad():\n",
    "  preds = model(test_seq.to(device), test_mask.to(device))\n",
    "  preds = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(preds, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  5,  0, ...,  2,  2,  2])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the predictions out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CEO', 'CHILD_OF', 'DATE_FOUNDED', 'DATE_OF_BIRTH',\n",
       "       'DATE_OF_DEATH', 'EDUCATED_AT', 'EMPLOYEE_OR_MEMBER_OF',\n",
       "       'FOUNDED_BY', 'HEADQUARTERS', 'NATIONALITY', 'PLACE_OF_BIRTH',\n",
       "       'PLACE_OF_RESIDENCE', 'POLITICAL_AFFILIATION', 'SPOUSE',\n",
       "       'SUBSIDIARY_OF'], dtype=object)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POLITICAL_AFFILIATION', 'EDUCATED_AT', 'CEO', ..., 'DATE_FOUNDED',\n",
       "       'DATE_FOUNDED', 'DATE_FOUNDED'], dtype=object)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.inverse_transform(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"propertyName\"] = label_encoder.inverse_transform(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passageText</th>\n",
       "      <th>passageId</th>\n",
       "      <th>propertyName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He is also chairman of Think Tank of Pakistan,...</td>\n",
       "      <td>14752:1502:1843</td>\n",
       "      <td>POLITICAL_AFFILIATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He is PhD in Mass Communication and Gold Medal...</td>\n",
       "      <td>14752:399:623</td>\n",
       "      <td>EDUCATED_AT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dr Muhammad Ather Khurram is Chief Executive O...</td>\n",
       "      <td>14752:27:189</td>\n",
       "      <td>CEO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He was born in Glasgow the son of Thomas Thoms...</td>\n",
       "      <td>14194:254:346</td>\n",
       "      <td>POLITICAL_AFFILIATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rex G. Maughan is the founder, president, and ...</td>\n",
       "      <td>7038:13:188</td>\n",
       "      <td>CEO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>Groove was initially developed by Lotus Notes ...</td>\n",
       "      <td>5316:907:1095</td>\n",
       "      <td>DATE_FOUNDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>In 1987, the privately held company was fully ...</td>\n",
       "      <td>19897:429:583</td>\n",
       "      <td>DATE_FOUNDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>The station is owned by the Fox Television Sta...</td>\n",
       "      <td>1533:136:219</td>\n",
       "      <td>DATE_FOUNDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>It was built for Howard &amp; Wyndham Ltd under it...</td>\n",
       "      <td>17680:77:263</td>\n",
       "      <td>DATE_FOUNDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>It was the former home of Taliban leader Mulla...</td>\n",
       "      <td>8221:130:296</td>\n",
       "      <td>DATE_FOUNDED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1454 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            passageText        passageId  \\\n",
       "0     He is also chairman of Think Tank of Pakistan,...  14752:1502:1843   \n",
       "1     He is PhD in Mass Communication and Gold Medal...    14752:399:623   \n",
       "2     Dr Muhammad Ather Khurram is Chief Executive O...     14752:27:189   \n",
       "3     He was born in Glasgow the son of Thomas Thoms...    14194:254:346   \n",
       "4     Rex G. Maughan is the founder, president, and ...      7038:13:188   \n",
       "...                                                 ...              ...   \n",
       "1449  Groove was initially developed by Lotus Notes ...    5316:907:1095   \n",
       "1450  In 1987, the privately held company was fully ...    19897:429:583   \n",
       "1451  The station is owned by the Fox Television Sta...     1533:136:219   \n",
       "1452  It was built for Howard & Wyndham Ltd under it...     17680:77:263   \n",
       "1453  It was the former home of Taliban leader Mulla...     8221:130:296   \n",
       "\n",
       "               propertyName  \n",
       "0     POLITICAL_AFFILIATION  \n",
       "1               EDUCATED_AT  \n",
       "2                       CEO  \n",
       "3     POLITICAL_AFFILIATION  \n",
       "4                       CEO  \n",
       "...                     ...  \n",
       "1449           DATE_FOUNDED  \n",
       "1450           DATE_FOUNDED  \n",
       "1451           DATE_FOUNDED  \n",
       "1452           DATE_FOUNDED  \n",
       "1453           DATE_FOUNDED  \n",
       "\n",
       "[1454 rows x 3 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>propertyId</th>\n",
       "      <th>propertyName</th>\n",
       "      <th>propertyDescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>EDUCATED_AT</td>\n",
       "      <td>Describes the relationship between a person an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SUBSIDIARY_OF</td>\n",
       "      <td>Describes the relationship between a parent co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>DATE_OF_DEATH</td>\n",
       "      <td>Describes the date of death of a person.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>NATIONALITY</td>\n",
       "      <td>Describes he country of a person's citizenship...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>HEADQUARTERS</td>\n",
       "      <td>Describes the specific location where an organ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>FOUNDED_BY</td>\n",
       "      <td>Describes the relationship between an organiza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25</td>\n",
       "      <td>SPOUSE</td>\n",
       "      <td>Describes the relationship between a person an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>CEO</td>\n",
       "      <td>Describes the relationship between an organiza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11</td>\n",
       "      <td>PLACE_OF_RESIDENCE</td>\n",
       "      <td>Describes the relationship between a person an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5</td>\n",
       "      <td>DATE_FOUNDED</td>\n",
       "      <td>Describes the founding date of a company.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>45</td>\n",
       "      <td>POLITICAL_AFFILIATION</td>\n",
       "      <td>Describes the relationship between a person an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12</td>\n",
       "      <td>PLACE_OF_BIRTH</td>\n",
       "      <td>Describes the relationship between a person an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>EMPLOYEE_OR_MEMBER_OF</td>\n",
       "      <td>Describes the previous/current employer of a p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>34</td>\n",
       "      <td>CHILD_OF</td>\n",
       "      <td>Describes the relationship between a person an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>15</td>\n",
       "      <td>DATE_OF_BIRTH</td>\n",
       "      <td>Describes the date of birth of a person.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    propertyId           propertyName  \\\n",
       "0            9            EDUCATED_AT   \n",
       "1            1          SUBSIDIARY_OF   \n",
       "2           14          DATE_OF_DEATH   \n",
       "3           10            NATIONALITY   \n",
       "5            6           HEADQUARTERS   \n",
       "10           2             FOUNDED_BY   \n",
       "11          25                 SPOUSE   \n",
       "13           4                    CEO   \n",
       "18          11     PLACE_OF_RESIDENCE   \n",
       "20           5           DATE_FOUNDED   \n",
       "24          45  POLITICAL_AFFILIATION   \n",
       "25          12         PLACE_OF_BIRTH   \n",
       "27           3  EMPLOYEE_OR_MEMBER_OF   \n",
       "36          34               CHILD_OF   \n",
       "84          15          DATE_OF_BIRTH   \n",
       "\n",
       "                                  propertyDescription  \n",
       "0   Describes the relationship between a person an...  \n",
       "1   Describes the relationship between a parent co...  \n",
       "2            Describes the date of death of a person.  \n",
       "3   Describes he country of a person's citizenship...  \n",
       "5   Describes the specific location where an organ...  \n",
       "10  Describes the relationship between an organiza...  \n",
       "11  Describes the relationship between a person an...  \n",
       "13  Describes the relationship between an organiza...  \n",
       "18  Describes the relationship between a person an...  \n",
       "20          Describes the founding date of a company.  \n",
       "24  Describes the relationship between a person an...  \n",
       "25  Describes the relationship between a person an...  \n",
       "27  Describes the previous/current employer of a p...  \n",
       "36  Describes the relationship between a person an...  \n",
       "84           Describes the date of birth of a person.  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"propertyId\",\"propertyName\",\"propertyDescription\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_df = pd.merge(test_df, df[[\"propertyId\",\"propertyName\",\"propertyDescription\"]].drop_duplicates(),how=\"left\", on=\"propertyName\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_df.to_csv(\"output.tsv\",sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passageText</th>\n",
       "      <th>passageId</th>\n",
       "      <th>propertyName</th>\n",
       "      <th>propertyId</th>\n",
       "      <th>propertyDescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He is also chairman of Think Tank of Pakistan,...</td>\n",
       "      <td>14752:1502:1843</td>\n",
       "      <td>POLITICAL_AFFILIATION</td>\n",
       "      <td>45</td>\n",
       "      <td>Describes the relationship between a person an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He is PhD in Mass Communication and Gold Medal...</td>\n",
       "      <td>14752:399:623</td>\n",
       "      <td>EDUCATED_AT</td>\n",
       "      <td>9</td>\n",
       "      <td>Describes the relationship between a person an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dr Muhammad Ather Khurram is Chief Executive O...</td>\n",
       "      <td>14752:27:189</td>\n",
       "      <td>CEO</td>\n",
       "      <td>4</td>\n",
       "      <td>Describes the relationship between an organiza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He was born in Glasgow the son of Thomas Thoms...</td>\n",
       "      <td>14194:254:346</td>\n",
       "      <td>POLITICAL_AFFILIATION</td>\n",
       "      <td>45</td>\n",
       "      <td>Describes the relationship between a person an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rex G. Maughan is the founder, president, and ...</td>\n",
       "      <td>7038:13:188</td>\n",
       "      <td>CEO</td>\n",
       "      <td>4</td>\n",
       "      <td>Describes the relationship between an organiza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>Groove was initially developed by Lotus Notes ...</td>\n",
       "      <td>5316:907:1095</td>\n",
       "      <td>DATE_FOUNDED</td>\n",
       "      <td>5</td>\n",
       "      <td>Describes the founding date of a company.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>In 1987, the privately held company was fully ...</td>\n",
       "      <td>19897:429:583</td>\n",
       "      <td>DATE_FOUNDED</td>\n",
       "      <td>5</td>\n",
       "      <td>Describes the founding date of a company.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>The station is owned by the Fox Television Sta...</td>\n",
       "      <td>1533:136:219</td>\n",
       "      <td>DATE_FOUNDED</td>\n",
       "      <td>5</td>\n",
       "      <td>Describes the founding date of a company.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>It was built for Howard &amp; Wyndham Ltd under it...</td>\n",
       "      <td>17680:77:263</td>\n",
       "      <td>DATE_FOUNDED</td>\n",
       "      <td>5</td>\n",
       "      <td>Describes the founding date of a company.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>It was the former home of Taliban leader Mulla...</td>\n",
       "      <td>8221:130:296</td>\n",
       "      <td>DATE_FOUNDED</td>\n",
       "      <td>5</td>\n",
       "      <td>Describes the founding date of a company.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1454 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            passageText        passageId  \\\n",
       "0     He is also chairman of Think Tank of Pakistan,...  14752:1502:1843   \n",
       "1     He is PhD in Mass Communication and Gold Medal...    14752:399:623   \n",
       "2     Dr Muhammad Ather Khurram is Chief Executive O...     14752:27:189   \n",
       "3     He was born in Glasgow the son of Thomas Thoms...    14194:254:346   \n",
       "4     Rex G. Maughan is the founder, president, and ...      7038:13:188   \n",
       "...                                                 ...              ...   \n",
       "1449  Groove was initially developed by Lotus Notes ...    5316:907:1095   \n",
       "1450  In 1987, the privately held company was fully ...    19897:429:583   \n",
       "1451  The station is owned by the Fox Television Sta...     1533:136:219   \n",
       "1452  It was built for Howard & Wyndham Ltd under it...     17680:77:263   \n",
       "1453  It was the former home of Taliban leader Mulla...     8221:130:296   \n",
       "\n",
       "               propertyName  propertyId  \\\n",
       "0     POLITICAL_AFFILIATION          45   \n",
       "1               EDUCATED_AT           9   \n",
       "2                       CEO           4   \n",
       "3     POLITICAL_AFFILIATION          45   \n",
       "4                       CEO           4   \n",
       "...                     ...         ...   \n",
       "1449           DATE_FOUNDED           5   \n",
       "1450           DATE_FOUNDED           5   \n",
       "1451           DATE_FOUNDED           5   \n",
       "1452           DATE_FOUNDED           5   \n",
       "1453           DATE_FOUNDED           5   \n",
       "\n",
       "                                    propertyDescription  \n",
       "0     Describes the relationship between a person an...  \n",
       "1     Describes the relationship between a person an...  \n",
       "2     Describes the relationship between an organiza...  \n",
       "3     Describes the relationship between a person an...  \n",
       "4     Describes the relationship between an organiza...  \n",
       "...                                                 ...  \n",
       "1449          Describes the founding date of a company.  \n",
       "1450          Describes the founding date of a company.  \n",
       "1451          Describes the founding date of a company.  \n",
       "1452          Describes the founding date of a company.  \n",
       "1453          Describes the founding date of a company.  \n",
       "\n",
       "[1454 rows x 5 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
